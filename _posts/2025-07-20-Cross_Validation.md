---
layout: post
title:  "교차검증(Cross Validation)"
date:   2025-07-20 09:00:00 +0900
categories: [머신러닝, 인공지능, 데이터과학]
tags: [머신러닝기초]
---

안녕하세요, **AI 공부 블로그**에 오신 것을 환영합니다! 
오늘은 머신러닝과 딥러닝 공부를 시작하면서 꼭 알아야 할 기본 개념인 교차 검증에 대해서 알아보겠습니다.

---
## 교차 검증(Cross Validation)

모델 평가 시 학습 데이터와 테스트 데이터 한 번만 분할 시 평가의 위험 부담이 큼. 뿐만 아니라, 데이터 분할 방식 따라 과적합 등의 문제로 인해 모델 성능이 변하여, 모델 일반화 능력 신뢰 어려움.
이러한 문제 보완 위해 사용하는 검증 방식을 바로 **교차 검증**이라고 함. 

※ 과적합이란?
ML 모델이 학습된 데이터에선 정확한 예측을 하지만, 새로운 데이터에 대해서는 그렇지 못할 때 발생하는 현상을 뜻한다.

- 종류 : 홀드 아웃, K-Fold 교차 검증


---
## K-폴드 교차 검증(K-Fold Cross Validation)


*   **K-폴드 교차 검증이란?**
    *   전체 데이터 K개 동등 폴드(부분)로 분할
    *   K번 반복 수행. 매번 다른 1개의 폴드를 테스트 데이터. 나머지 (K-1)개 폴드를 학습 데이터로 사용하여 모델 학습 및 평가 진행.
    *   마지막에는 K번의 평가 결과를 평균 내서 최종 모델 성능으로 사용. 데이터 편향 따른 성능 변동 줄이고 모델 성능을 더 **강건(Robust)**하게 평가 가능.

### ** K 값 선택, 얼마나 중요할까?**

그럼 이 'K'를 몇으로 정해야 할까요? K 값 선택은 모델 평가의 안정성과 계산 비용에 영향을 미쳐요!

*   **K가 작을 때 (예: K=3 또는 K=5)**
    *   **장점:**  계산 비용 적음. 모델 학습 시간 짧음.
    *   **단점:** 각 폴드 데이터 양 많음. 평가 결과 분산 커질 수 있음. 모든 데이터 골고루 사용 불가. 평가 편향 가능성 존재.
*   **K가 클 때 (예: K=10 또는 K=N(Leave-One-Out CV))**
    *   **장점:** 모든 데이터 골고루 학습 및 평가 사용. 평가 결과 편향 적음. 모델 성능 더 정확하게 추정 가능.
    *   **단점:** 계산 비용 매우 많음. 모델 학습 시간 김. 특히 K=N (Leave-One-Out CV) 시 N번 학습/평가 필수. 데이터 크면 현실적으로 적용 불가.
*   **어떤 K를 선택할까?**
    *   일반적으로 K=5 또는 K=10 가장 보편적 사용. 계산 비용, 평가 안정성 사이에서 좋은 균형점.
    *   단, 데이터셋 크기, 모델 복잡성, 컴퓨팅 자원 등 고려 필요. 최적 K 값 선택.

---

| K 값 범위                 | 장점                                              | 단점                                                        |
| :------------------------ | :------------------------------------------------ | :---------------------------------------------------------- |
| **K가 작을 때**           | - 계산 비용 적음                                  | - 평가 결과 분산 커질 수 있음 (덜 안정적)                   |
| (예: 3, 5)                | - 모델 학습 시간 짧음                             | - 데이터 편향 생길 가능성 있음                              |
|                           |                                                   | - 모든 데이터 골고루 활용 불가                              |
| **K가 클 때**             | - 모든 데이터 골고루 활용 평가 신뢰도 높음        | - 계산 비용 매우 많음                                       |
| (예: 10, N(LOOCV))         | - 평가 결과 편향 적음 (더 정확한 성능 추정)       | - 모델 학습 시간 매우 김                                    |
|                           |                                                   | - 데이터 많으면 현실적으로 사용 불가 (특히 LOOCV)           |

---