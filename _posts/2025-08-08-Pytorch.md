---
layout: post
title:  "Pytorch"
date:   2025-08-08 16:00:00 +0900
categories: [딥러닝, 인공지능, 데이터과학]
tags: [딥러닝 기초]
---
---
## 1. Pytorch와 TensorFlow
---
Pytorch와 TensorFlow 모두 딥러닝 분야에서 가장 대중적으로 사용되는 프레임 워크입니다.
<br>
**TensorFlow**의 경우, 구글리서치의 구글브레인 팀이 공개한 라이브러리로써, Pytorch보다 먼저 상용화 되어 산업 분야에서 매우 큰 생태계를 형성하고 있습니다. TensorFlow의 경우, 초기에는 정적 계산 그래프 방식을 통하여 배포 시의 성능 최적화를 중점으로 두었습니다. 특히 대규모 환경에서의 안정적인 운영과 다양한 플랫폼으로의 배포를 위한 풍부한 도구들을 제공합니다.
하지만 이러한 정적 계산 그래프방식은 디버깅의 어려움과 유연성 부족이라는 단점을 가지고 있어, 2.0 버전부터는 Eager Execution을 도입하여, Pytorch와 마찬가지로 동적 계산 그래프 방식을 지원하게 되었습니다.

 ※ Eager Excution : 연산을 즉시 실행하고 결과값을 알려주는 방식

**Pytorch**의 경우, Facebook(현 Meta)의 AI연구팀에서 개발한 머신러닝 라이브러리로써, Define-by-Run방식을 통해 동적 계산 그래프 방식을 채택하고 있습니다. 이 방식은 코드를 실행하는 동시에 그래프를 구성하기 때문에 개발자가 모델의 흐름을 직관적으로 이해하고 디버깅하기 매우 용이합니다. 이러한 유연성 덕분에 연구 개발 단계에서 새로운 아이디어를 빠르게 실험하고 프로토타이핑하는 데 매우 효과적입니다.
pytorch는 현재 연구 및 개발 분야에서 빠르게 성장하고 있으며 이를 바탕으로, 과거에는 배포와 관련된 도구가 다양해지고 있습니다.

---

## 2. Pytorch의 텐서란
---
Pytorch에서 Tensor(텐서)란 딥러닝의 모델의 입력, 출력, 모델의 가중치를 표현하는 데 사용되는 자료구조입니다. 
즉, 이러한 입,출력 및 가중치를 표현하기 위해 다차원적인 숫자 데이터의 형태를 띠는데, 이를 표현하고 연산하기 위해 '텐서'라는 다차원 배열 자료구조를 사용하는 것입니다.
쉽게 말해, 텐서는 배열이나 행렬과 비슷한 자료구조입니다.

### tensor와 numpy array비교

Tensor의 경우, ndarray와 같이 다차원을 배열을 다루기 위해 사용되며, 다양한 연산을 사용할 수 있다. 하지만 ndarray에서 지원하지 않는 GPU 가속을 통해, 병렬 연산에 최적화되어있으며, 역전파 계산을 위한 자동미분기능(autograd)을 내장하고 있다.



| 분류	 | 특징	       | PyTorch 텐서                                  | 	NumPy ndarray                   |
|-----|-----------|--------------------------------------------------------------|----------------------------------------------------|
| 공통점 | 자료구조      | 	다차원 배열                             | 	다차원 배열                  |
|     | 연산 기능     | 	다양한 수치 연산 (사칙연산, 행렬 곱셈 등) 및 데이터 조작 기능 지원                    | 	다양한 수치 연산 (사칙연산, 행렬 곱셈 등) 및 데이터 조작 기능 지원          |
|     | 주요 데이터 표현 | 	딥러닝 모델의 입력, 출력, 가중치 등 숫자 데이터를 표현	                           | 일반적인 수치 데이터 (과학 데이터, 이미지, 신호 등)를 표현                |
| 차이점 | GPU 지원    | 	GPU 가속을 기본으로 지원하여 대규모 병렬 연산에 최적화	                           | CPU에서 주로 작동하며, GPU 가속을 자체적으로 지원하지 않음               |
|     | 자동 미분     | 	자동 미분 기능(autograd)을 내장하여 역전파 계산에 필수적임	                      | 자동 미분 기능을 제공하지 않음                                  |
|     | 목적 및 활용	  | 주로 딥러닝 모델의 개발, 학습, 추론 등 딥러닝 생태계에 특화	                         | 범용적인 과학 계산, 데이터 분석, 그리고 딥러닝에서 데이터 전처리 등 다양한 분야에 활용 |
|     | 데이터 공유    | 	NumPy 배열과 변환 시 (예: .numpy(), .from_numpy()) 대부분 데이터를 공유합니다. | 	PyTorch 텐서와 변환 시 데이터를 공유합니다.                      |

---
## 3. PyTorch 텐서의 주요 기능 및 메서드 정리
---
PyTorch 텐서는 데이터를 효율적으로 저장하고, 조작하며, 딥러닝 연산에 최적화된 다양한 메서드와 함수를 제공합니다.

1. 텐서 생성 및 초기화
`torch.tensor(data)`: Python 리스트, NumPy 배열 등의 데이터를 텐서로 만듭니다.
`torch.zeros(shape)`, `torch.ones(shape)`: 모든 값이 0 또는 1인 텐서를 만듭니다.
`torch.rand(shape)`, `torch.randn(shape)`: 균일 분포 또는 표준 정규 분포의 난수로 채워진 텐서를 만듭니다.
`torch.empty(shape)`: 초기화되지 않은 텐서를 생성합니다.
<br>
2. 텐서 정보 확인
`tensor.shape` 또는 `tensor.size()`: 텐서의 크기(각 차원의 길이)를 알려줍니다.
`tensor.dtype`: 텐서의 데이터 타입(예: `torch.float32`, `torch.int64`)을 알려줍니다.
`tensor.device`: 텐서가 현재 저장된 장치(CPU 또는 GPU)를 알려줍니다.
<br>
3. 텐서 연산
기본 산술 연산: +, -, *, / (요소별 연산). `torch.add()`, `torch.mul()` 등 함수 형태로도 쓸 수 있습니다.
행렬 곱셈: `torch.matmul(tensor1, tensor2)` 또는 `tensor1 @ tensor2`.
요소별 수학 함수: `torch.sqrt()`, `torch.exp()`, `torch.log()`, `torch.abs()` 등 다양한 수학 함수를 텐서에 적용합니다.
집계(Aggregation) 연산: `tensor.sum()`, `tensor.mean()`, `tensor.max()`, `tensor.min()` 등을 사용하여 특정 차원(dim)을 기준으로 값들을 합치거나 평균을 낼 수 있습니다.
<br>
4. 텐서 형태 변경 (Shape/View Manipulation)
`tensor.view(new_shape)`: 텐서의 모양을 변경하지만 데이터는 복사하지 않습니다. (데이터가 메모리상 연속적일 때)
`tensor.reshape(new_shape)`: `view`와 유사하게 모양을 변경하며, 필요하면 데이터를 복사하여 연속성을 유지합니다. (더 유연)
`tensor.transpose(dim0, dim1)`: 두 차원의 위치를 바꿉니다. `tensor.T` (`.t()`)는 2D 텐서의 전치입니다.
`tensor.squeeze()`: 차원의 길이가 1인 차원을 제거합니다.
`tensor.unsqueeze(dim)`: 특정 위치에 길이가 1인 새로운 차원을 추가합니다.
<br>
5. 인덱싱 및 슬라이싱
NumPy처럼 `tensor[idx, ...]` 형태로 특정 요소나 부분 배열에 접근할 수 있습니다.
`torch.cat([tensor1, tensor2], dim)`: 여러 텐서를 지정된 차원을 기준으로 연결합니다.
<br>
6. NumPy 호환 및 장치 이동
`tensor.numpy()`: PyTorch 텐서를 NumPy ndarray로 변환합니다. (메모리를 공유합니다.)
`torch.from_numpy(ndarray)`: NumPy ndarray를 PyTorch 텐서로 변환합니다. (메모리를 공유합니다.)
`tensor.to(device)`: 텐서를 CPU에서 GPU로(예: `tensor.to('cuda')`) 또는 GPU에서 CPU로(예: `tensor.to('cpu')`) 이동시킵니다.
<br>
7. 자동 미분(Autograd) 관련
`tensor.requires_grad = True`: 이 텐서에 대한 모든 연산을 추적하여, 나중에 `tensor.backward()`를 호출할 때 기울기(gradient)를 계산할 수 있도록 합니다.
`tensor.detach()`: 현재 계산 그래프에서 텐서를 분리하여, 이후 연산이 기울기 추적에 영향을 주지 않도록 합니다.