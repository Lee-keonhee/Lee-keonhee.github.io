---
layout: post
title:  "편향(Bias)와 분산(Variance)"
date:   2025-07-20 09:00:00 +0900
categories: [머신러닝, 인공지능, 데이터과학]
tags: [머신러닝기초]
---

안녕하세요, **AI 공부 블로그**에 오신 것을 환영합니다! 
오늘은 머신러닝과 딥러닝 공부를 시작하면서 꼭 알아야 할 기본인 편향과 분산에 대해서 알아보겠습니다.


## ⚖ 편향(Bias)과 분산(Variance): 모델의 완벽함과 유연함 사이!

모델을 학습시키다 보면 **편향(Bias)**과 **분산(Variance)**이라는 두 가지 문제가 생깁니다. 이 둘은 마치 서로 반대 방향으로 움직이는 관계를 가지고 있습니다.

*   **편향 (Bias)**
    *   **정의:** 모델이 학습 데이터에 있는 **핵심적인 패턴을 제대로 파악하지 못해서 발생하는 오류**. 모델이 너무 단순해서 복잡한 데이터를 잘 설명하지 못할 때 발생.
    *   **특징:** 높을 경우, '과소적합(Underfitting)'발생, 학습 데이터, 테스트 데이터에 대한 오차가 모두 큼.

*   **분산 (Variance)**
    *   **정의:** 모델이 학습 데이터의 **아주 사소한 변화나 노이즈까지 과하게 학습해서 발생하는 오류**. 모델이 너무 복잡해서 학습 데이터를 과도하게 학습.
    *   **특징:** 높을 경우, '과대적합(Overfitting)'발생. 학습 데이터에 대한 오차가 적지만, 테스트 데이터에 대한 예측 성능이 떨어짐.

### ** 편향-분산 트레이드오프(Bias-Variance Trade-off)**

*   **편향-분산 트레이드오프**: 편향을 줄이려고 모델을 복잡하게 만들면 분산이 커지고, 분산을 줄이려고 모델을 단순하게 만들면 편향이 커짐.
*   **목표**: 편향과 분산의 적절한 균형 달성 필수적임. 모델은 지나친 단순성 또는 과도한 복잡성 모두 지양함. 이러한 최적 지점 확보 시에만 신규 데이터에 대한 우수한 성능 보장 가능함.

---
